{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c9c5a60",
   "metadata": {},
   "source": [
    "# Exercise 1 - Classification to predict student admission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daf0e59",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c28efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7111aa8b",
   "metadata": {},
   "source": [
    "## Exercise steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf011d53",
   "metadata": {},
   "source": [
    "### a. Logistic regression classifier with linear decision boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46294c8",
   "metadata": {},
   "source": [
    "#### a) Read the data from file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595ac345",
   "metadata": {},
   "source": [
    "In a similar way as for the exercise of the previous week, read the training data from file `student-dataset-train.csv`. The first two columns are $x_{1}$ and $x_{2}$. The last column holds the class label $y$. Build the design matrix $X$ as follow:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07903ccd",
   "metadata": {},
   "source": [
    "<center>$X = \\left(\\begin{array}{ccc} \n",
    "        1 &   x_{1,1} & x_{1,2} \\\\\n",
    "        1 &   \\vdots  & \\vdots  \\\\\n",
    "        1 &   x_{N,1} & x_{N,2}\n",
    "           \\end{array}\\right)$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679d31ec",
   "metadata": {},
   "source": [
    "Check that the shape of $X$ is (100,3) and that the shape of $y$ is (100,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922120d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eb2b3e",
   "metadata": {},
   "source": [
    "#### b) Implement a z-norm normalization of the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedfd222",
   "metadata": {},
   "source": [
    "You need to store the normalization values $(\\mu, \\sigma)$ for later as they will be needed to normalize the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "814f8bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf8fced",
   "metadata": {},
   "source": [
    "#### c) Implement a sigmoid function $g(z) = \\frac{1}{1+e^{-z}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6bc4d3",
   "metadata": {},
   "source": [
    "Use numpy to compute the exp so that your function can take numpy arrays as input. Check your implementation by plotting the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f479a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3d2958",
   "metadata": {},
   "source": [
    "#### d) Implement the hypothesis function $h_{\\theta}(\\mathbf{x})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fb80e2",
   "metadata": {},
   "source": [
    "Hint: implement it so that the computation can take the full array $X$ with $h(\\mathbf{x})$ broadcasted to all training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d66dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e29c2e3",
   "metadata": {},
   "source": [
    "#### e) Implement the objective function $J(\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b12f3ac",
   "metadata": {},
   "source": [
    "<center>$J(\\theta) = \\frac{1}{N} \\sum_{n=1}^{N} y_{n} \\log h_{\\theta}(\\mathbf{x_{n}}) + (1-y_{n}) \\log (1 - h_{\\theta} (\\mathbf{x_{n}}))$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edfbb39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cf517b",
   "metadata": {},
   "source": [
    "#### f) Implement the gradient ascent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da42fed9",
   "metadata": {},
   "source": [
    "In a similar way as in PW02 and PW03, implement the gradient ascent with the update rule:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6135d3",
   "metadata": {},
   "source": [
    "<center>$\\theta_{i} \\leftarrow \\theta_{i} + \\alpha \\frac{1}{N} \\sum_{n=1}^{N} (y_{n} - h_{\\theta}(\\mathbf{x}_{n})) x_{n,i}$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5277e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9993050d",
   "metadata": {},
   "source": [
    "#### g) Test your implementation by running a gradient ascent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeea57c",
   "metadata": {},
   "source": [
    "Hints: use a small $\\alpha$. e.g. $0.001$,  store the evolution of the objective function $J(\\theta)$ during the epochs to make a plot, use a large number of epochs, e.g. $2000000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad5cd402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c6dee7",
   "metadata": {},
   "source": [
    "#### h) Compute the correct classification rate on `student-dataset-test.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11206c83",
   "metadata": {},
   "source": [
    "Compute the correct classification rate on `student-dataset-test.csv` after convergence as you have an estimator of the posterior probabilities with:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd1e565",
   "metadata": {},
   "source": [
    "<center>$P(y_{n}=1|\\mathbf{x_{n}};\\theta) = h_{\\theta}(\\mathbf{x_{n}})$</center>\n",
    "<center>$P(y_{n}=0|\\mathbf{x_{n}};\\theta) = 1 - h_{\\theta}(\\mathbf{x_{n}})$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719bfe0a",
   "metadata": {},
   "source": [
    "This means that you can take the decisions $\\hat{y}_{n} = 1$ if $h_{\\theta}(\\mathbf{x_{n}}) \\geq 0.5$ and $\\hat{y}_{n} = 0$ if $h_{\\theta}(\\mathbf{x_{n}}) < 0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a333f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de5cb5a",
   "metadata": {},
   "source": [
    "#### i) Draw the decision boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fab6839",
   "metadata": {},
   "source": [
    "Draw the decision boundary of your system on top of the scatter plot of the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec0a3e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33157fe",
   "metadata": {},
   "source": [
    "#### j) Compare the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e518484b",
   "metadata": {},
   "source": [
    "Compare the performance of the logistic regression system with the ones of previous's week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b628d369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your observation here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29883176",
   "metadata": {},
   "source": [
    "### b. Optional - Stochastic gradient ascent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16686a85",
   "metadata": {},
   "source": [
    "Redo the experiments of 2.a with a stochastic gradient ascent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01bec6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20885c0a",
   "metadata": {},
   "source": [
    "### c. Logistic regression classifier with non-linear decision boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2e0a1e",
   "metadata": {},
   "source": [
    "Redo the experiments of 2.a by increasing the complexity of the model in order to have a non-linear decision boundary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad8f75e",
   "metadata": {},
   "source": [
    "<center>$h_{\\theta}(\\mathbf{x}) = g(\\theta_{0} + \\theta_{1} x_{1} + \\theta_{2} x_{2} + \\theta_{3} x_{1}^{2} + \\theta_{4} x_{2}^{2} + \\theta_{5} x_{1}x_{2} + \\ldots)$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc7851a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9995e78",
   "metadata": {},
   "source": [
    "### d. Using SciKit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420c64c4",
   "metadata": {},
   "source": [
    "Redo one of the exercise a. or c. using SciKit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c918199",
   "metadata": {},
   "source": [
    "1. Read the documentation of the function `SGDClassifier()` available in the toolkit SciKit Learn. This function implements stochastic gradient descent training for different linear systems such as Logistic Regression. For a logistic regression, the `loss` parameter should be set to `\"log\"`.\n",
    "1. Use the `fit()` and `predict()` methods of this classifier on the student data.\n",
    "1. Compute the performances and compare it to your own implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "627bdd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb502af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
