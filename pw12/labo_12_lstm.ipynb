{"cells":[{"cell_type":"markdown","metadata":{"id":"eP22jUnjMFy7"},"source":["# Recurrent artificial neural networks\n","# Long Short-Term Memory - LSTM\n","--------\n","\n","This notebook will guide you through the training and testing of a LSTM network in the task of predicting the speed of a runner for a given slope by using her/his previous speeds during a given race."]},{"cell_type":"markdown","metadata":{"id":"HDdx-IFTNIUj"},"source":["Before running the cells in this notebook you have to upload some files with data from some races and the Python module for parsing those files and preparing a dataset.\n","### left panel -> Files -> Upload\n","Then select the compressed folder **strava.zip** and the Python module **strava.py**\n","\n","### OR\n","Uncomment and update the code in the following cell if your data is in your google drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SXY6P9d-KLZa"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/content/drive')\n","\n","#!cp 'drive/My Drive/Colab Notebooks/strava.zip' .\n","#!cp 'drive/My Drive/Colab Notebooks/strava.py' ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mti6ZrSzNQ0Q"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"WpSz9Uj2OYwo"},"source":["Let us start by loading some Python modules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"92_Dj5_TiZgt"},"outputs":[],"source":["import numpy as np\n","from matplotlib import pyplot as pl\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","import os\n","\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","\n","import strava as st"]},{"cell_type":"markdown","metadata":{"id":"TETKvjYaOa5L"},"source":["Then, let us unzip the compressed file you uploaded"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lY3LInPq1OdN"},"outputs":[],"source":["if os.path.exists('strava'):\n","  print('Data are already in folder')\n","else:\n","  if os.path.exists('strava.zip'):\n","    !unzip strava.zip\n","  else:\n","    print('You must upload the data first!')"]},{"cell_type":"markdown","metadata":{"id":"-cbiSYldOvQI"},"source":["Declare some constants"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7I5sJxxRi6XP"},"outputs":[],"source":["PATH_DATA = 'strava'\n","\n","FEATURES = ['time', 'speed', 'slope']    # selected from ['time', 'elevation', 'distance', 'speed', 'slope']\n","SPEED_OUTLIER = 8.0                      # speed > 30km/h\n","SLOPE_OUTLIER = 80                       # slope > +-80%\n","TIME_PERIOD = 1*60                       # period of time to average\n","SEGMENT_LENGTH = 100                     # length of the segment to average data\n","AVERAGE_SPEED_TH = 2.4                   # threshold to further clean the dataset"]},{"cell_type":"markdown","metadata":{"id":"mZR5kdjEPPib"},"source":["### Read the data\n","Parse the files in the **strava** folder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AY1u8L_Cj4ae"},"outputs":[],"source":["importer = st.RunImport(SPEED_OUTLIER, SLOPE_OUTLIER, TIME_PERIOD, SEGMENT_LENGTH, AVERAGE_SPEED_TH)\n","dataset = importer.import_path(PATH_DATA)"]},{"cell_type":"markdown","metadata":{"id":"7LUylxBpPX_y"},"source":["### Example of a race\n","The following cell shows an example of the data from a race"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eWZ2oGcckpNC"},"outputs":[],"source":["st.plot_race(dataset, np.random.randint(dataset['race'].max()))"]},{"cell_type":"markdown","metadata":{"id":"nIcLX03cD1Qg"},"source":["### Normalize the dataset\n","The following cell normalizes the features into the interval [0, 1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oIAKyjupj6N0"},"outputs":[],"source":["# Copy the dataset before normalisation, feature selection, numpy conversion, etc.\n","original_dataset = dataset.copy(deep=True)\n","min_speed = original_dataset['speed'].min()\n","max_speed = original_dataset['speed'].max()\n","\n","#normalize only the selected features\n","#transform to numpy\n","normalized_dataset = dataset.filter(items=FEATURES).values\n","scaler = MinMaxScaler()\n","scaler.fit(normalized_dataset)\n","normalized_dataset = scaler.transform(normalized_dataset)\n","#transform back to dataframe\n","normalized_dataset = pd.DataFrame(normalized_dataset, index=dataset.index, columns=FEATURES)\n","\n","#update the dataset with the new values\n","dataset.update(normalized_dataset)\n","\n","print(\"Min (per features):\", scaler.data_min_)\n","print(\"Max (per features):\", scaler.data_max_)\n","display(dataset.head())"]},{"cell_type":"markdown","metadata":{"id":"dsOdXWotEZZ0"},"source":["### Create a training and a testing subset\n","Split the dataset into training and testing\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C7X9I15973h2"},"outputs":[],"source":["TIMESTEPS = 10                   #define sequence length\n","TEST_SIZE = 0.2                  #value between ]0;1[\n","TRAINING_SIZE = 1 - TEST_SIZE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZA0whhtAzebM"},"outputs":[],"source":["all_races = np.unique(dataset['race'])\n","print('Number of races', len(all_races))\n","RACES_TRAINING = int(np.floor(TRAINING_SIZE * len(all_races)))\n","races_train = np.random.choice(all_races, RACES_TRAINING, replace=False)\n","#print(races_training)\n","races_test = list(set(all_races) - set(races_train))\n","#print(races_test)\n","print(len(races_train), 'used during training --- Number of samples', np.sum(np.isin(dataset['race'], races_train)))\n","print(len(races_test), 'used during test\\t --- Number of samples', np.sum(np.isin(dataset['race'], races_test)))"]},{"cell_type":"markdown","metadata":{"id":"0Om2qCtsErTx"},"source":["### Create inputs and outputs\n","The folowing cell contains the function that will be used to create the inputs and outputs for training the models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0D-WVxnyV27C"},"outputs":[],"source":["#take a dataframe as input and return the splitted version with the prediction as a numpy array\n","def create_x_y(data, races):\n","  speed_index = data[FEATURES].columns.get_loc('speed') #get speed index\n","  slope_index = data[FEATURES].columns.get_loc('slope') #get slope index\n","  time_index = data[FEATURES].columns.get_loc('time') #get time index\n","  x = None\n","  y = None\n","\n","  #iterate over every race\n","  for r in races:\n","    #filter race\n","    race_df = data.loc[data['race'] == r]\n","    #filter features\n","    race_np = race_df[FEATURES].values\n","    #split into timesteps (timesteps + 1 to take the target value)\n","    race_np = [race_np[i:(i+TIMESTEPS+1)] for i in range(race_np.shape[0] - (TIMESTEPS+2))]\n","\n","    if len(race_np) == 0:\n","      print(\"Warning: not enough values in race\", r)\n","      continue\n","\n","    race_np = np.stack(race_np, axis=0)\n","\n","    temp_x = np.dstack([race_np[:,1:,time_index],       # last TIMESTEPS-1 times and next time\n","                       race_np[:,1:,slope_index],       # last TIMESTEPS-1 slopes and next slope\n","                       race_np[:,:-1,speed_index]])     # last TIMESTEPS speeds\n","    temp_y = race_np[:,-1, speed_index]                 # next speed\n","\n","    if x is None:\n","      x = temp_x\n","      y = temp_y\n","    else:\n","      x = np.append(x, temp_x, axis=0)\n","      y = np.append(y, temp_y, axis=0)\n","\n","  return x, y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8-2c-kYeixTe"},"outputs":[],"source":["print('original shape:', dataset.shape)\n","\n","X_train, y_train = create_x_y(dataset, races_train)\n","print(\"X_train shape:\", X_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n","\n","X_test, y_test = create_x_y(dataset, races_test)\n","print(\"X_test shape:\", X_test.shape)\n","print(\"y_test shape:\", y_test.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"CoaCY1UuE-41"},"source":["### Create a model and train it\n","The following cells create a LSTM network and train it with the training subset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N2P-kE4UrqfW"},"outputs":[],"source":["BATCH_SIZE = 64          # Size of the batch for training\n","NB_EPOCHS = 2    # Number of times the training dataset is presented\n","NB_UNITS = 1         # Number of LSTM units\n","\n","# Create and fit the LSTM network\n","model = Sequential()\n","model.add(LSTM(NB_UNITS, input_shape=(TIMESTEPS, len(FEATURES))))\n","#dense layer 1 : connect all LSTM cell to one cell -> output shape as (*, 1)\n","model.add(Dense(1))\n","\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8PogxVaDrwpw"},"outputs":[],"source":["history = model.fit(X_train, y_train, epochs=NB_EPOCHS, batch_size=BATCH_SIZE, verbose=1, validation_data=(X_test, y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sOqUQVOokMbQ"},"outputs":[],"source":["# Plot the training and testing\n","pl.plot(history.history['loss'], label='Training')\n","pl.plot(history.history['val_loss'], label='Testing')\n","pl.xlabel('epochs')\n","pl.ylabel('mse')\n","pl.legend()\n","pl.grid()"]},{"cell_type":"markdown","metadata":{"id":"jNMO8YIGFYeV"},"source":["### Evaluate the performance of the model\n","The following cell computes the correlation between the actual speed of the runner and the model's output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-PAqGxbW36wS"},"outputs":[],"source":["y_train_pred = model.predict(X_train)\n","y_test_pred = model.predict(X_test)\n","\n","print('Training correlation coefficient:', np.corrcoef(y_train.T, y_train_pred.T)[0,1])\n","print('Test correlation coefficient:', np.corrcoef(y_test.T, y_test_pred.T)[0,1])"]},{"cell_type":"markdown","metadata":{"id":"ZoJiIABHFuLt"},"source":["### Visualize the results\n","The following cell visualize the output of the LSTM for a single race in the testing subset and compare it with the actual speed of the runner"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BIkpE_IjzwwM"},"outputs":[],"source":["random_race = np.random.choice(races_test)\n","X, y = create_x_y(dataset, [random_race])\n","X_o, y_o = create_x_y(original_dataset, [random_race])            # select inputs and output from the unnormalized dataset also\n","\n","y_pred_o = model.predict(X) * (max_speed - min_speed) + min_speed # unnormalize the prediction\n","\n","pl.figure(figsize=(14,4))\n","pl.plot(X_o[:,-1,0], y_o, label='actual speed')\n","pl.plot(X_o[:,-1,0], y_pred_o, label='prediction')\n","pl.plot(X_o[:,-1,0], np.abs(y_o - y_pred_o[:,0]), label='abs. error')\n","pl.legend()\n","pl.title('race number: ' + str(random_race))\n","pl.xlabel('time [s]')\n","pl.ylabel('speed [m/s]');\n"]},{"cell_type":"markdown","metadata":{"id":"TxyflgKYVHno"},"source":["# Exercise\n","\n","1. Change the number of units and epochs of the LSTM network. Show the configuration that performed the best.\n","2. What is the largest error (speed prediction) you observed? Do you observe that most of those large errors show up for high speeds ? or low speeds? Why?\n","3. Using the predicted speeds for a given race, compute the expected time for a race and compute the difference between the real race time and the predicted race time in minutes. Provide the code of the cell that computes this prediction error."]},{"cell_type":"code","source":[],"metadata":{"id":"_ddar7QQX5p5"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.4.1"}},"nbformat":4,"nbformat_minor":0}