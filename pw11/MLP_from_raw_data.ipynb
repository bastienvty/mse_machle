{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ic-cqm0tbUc3"
   },
   "source": [
    "# Multilayer Perceptron from raw data\n",
    "This notebook will guide you through the use of the `keras` package to train a multilayer perceptron for handwritten digits classification. You are going to use the `mnist` dataset from LeCun et al. 1998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ND1Cf9lXbUc6"
   },
   "source": [
    "## Loading the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pvq0DhLtbUdE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as pl\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn import metrics as me\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vy0wRnm2bUde"
   },
   "source": [
    "## Using raw data to train a MLP\n",
    "First load the `mnist` dataset and normalize it to be in the range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8CKuJwcibUdi"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Split the training set into a training set and a validation set\n",
    "X_val = X_train[0:10000,:,:]\n",
    "X_train = X_train[10000:,:,:]\n",
    "y_val = y_train[0:10000]\n",
    "y_train = y_train[10000:]\n",
    "\n",
    "# Reshape the training data tensors so that each image is a vector\n",
    "X_train = X_train.reshape(50000, 784)\n",
    "X_val = X_val.reshape(10000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Scale the training data so that pixel intensity lies in [0,1]\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_val.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "n_classes = 10\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
    "Y_val = tf.keras.utils.to_categorical(y_val, n_classes)\n",
    "Y_test = tf.keras.utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01XwVeDNbUdv"
   },
   "source": [
    "Create the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DNgzrBJEbUd0"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(784,), activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Peiq9GR2bUeN"
   },
   "source": [
    "Define some constants and train the MLP. In order to perform the model selection process, you train each model with the train dataset and evaluate it with the validation dataset. The test set remains unseen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NBt-ReqIbUeR"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_epoch = 10\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size, epochs=n_epoch,\n",
    "                    verbose=1, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7u_zpHr5bUeb"
   },
   "source": [
    "Show the performance of the model. By observing the performance of your models on the validation set, you will choose a set of hyperparameters for your final model. The test set is still not used at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHXi21E1bUef"
   },
   "outputs": [],
   "source": [
    "pl.plot(history.history['loss'], label='Training')\n",
    "pl.plot(history.history['val_loss'], label='Validation')\n",
    "pl.legend()\n",
    "pl.grid()\n",
    "\n",
    "score = model.evaluate(X_val, Y_val, verbose=0)\n",
    "print('Validation score:', score[0])\n",
    "print('Validation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rG_CBQQl6Slh"
   },
   "source": [
    "Now that you have chosen your final model, you can finally evaluate its performance using the test set. It is important that the test set remains hidden for your model until this last step in order to have an unbiased estimate of the performance. Therefore, you should not run the following cell until you have chosen your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VK5BBZhr7EZo"
   },
   "outputs": [],
   "source": [
    "final_score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('FINAL RESULTS:')\n",
    "print('Test score:', final_score[0])\n",
    "print('Test accuracy:', final_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLuFK6MobUet"
   },
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PAjwjjrjbUex"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred, axis=-1)\n",
    "me.confusion_matrix(y_test, pred)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
