{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkLUJVa1bfNW"
   },
   "source": [
    "# Convolutional Neural Networks\n",
    "This notebook will guide you through the use of the `keras` package to train convolutional neural networks for handwritten digits classification. You are going to use the `mnist` dataset from LeCun et al. 1998."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjQUQygFbfNb"
   },
   "source": [
    "## Loading the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7O8MewabfNj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as pl\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input\n",
    "from sklearn import metrics as me\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbttXt8SbfOH"
   },
   "source": [
    "First, create some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jAR9jPgybfOO"
   },
   "outputs": [],
   "source": [
    "def build_grid_of_images(array):\n",
    "    assert len(array.shape) == 3\n",
    "    dim_0 = np.sqrt(array.shape[0])\n",
    "    assert dim_0.is_integer()\n",
    "    \n",
    "    temp_out = np.reshape(array, (dim_0, dim_0, array.shape[1], array.shape[2]))\n",
    "    temp_out = np.rollaxis(temp_out, 1, 3)\n",
    "    return np.reshape(temp_out, (dim_0*array.shape[1], dim_0*array.shape[2]))\n",
    "\n",
    "def plot_conv_layer_output(temp_out, title):\n",
    "    temp_to_plot = build_grid_of_images(temp_out)\n",
    "    pl.imshow(temp_to_plot, interpolation='nearest', cmap=pl.get_cmap('Greys'))\n",
    "    ax = pl.gca()\n",
    "    ax.set_xticks(np.arange(-0.5, temp_to_plot.shape[0]+0.5, temp_out.shape[1]))    \n",
    "    ax.set_yticks(np.arange(-0.5, temp_to_plot.shape[0]+0.5, temp_out.shape[2]))\n",
    "    pl.grid()\n",
    "    pl.tick_params(axis='both', which='both', bottom='off', top='off', left='off', right='off', labelbottom='off', labelleft='off')\n",
    "    pl.title(title)\n",
    "\n",
    "def plot_dense_layer_output(temp_out, title):\n",
    "    pl.bar(np.arange(temp_out.shape[1])-0.4, temp_out[0,:])\n",
    "    pl.xlim(-0.5, temp_out.shape[1])\n",
    "    pl.grid()\n",
    "    pl.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fVOW4jGbfOb"
   },
   "source": [
    "Load the `mnist` dataset and normalize in the range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2H2K3S4MbfOf"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Split the training set into a training set and a validation set\n",
    "X_val = X_train[0:10000,:,:]\n",
    "X_train = X_train[10000:,:,:]\n",
    "y_val = y_train[0:10000]\n",
    "y_train = y_train[10000:]\n",
    "\n",
    "n_train, height, width = X_train.shape\n",
    "n_val, _, _ = X_val.shape\n",
    "n_test, _, _ = X_test.shape\n",
    "\n",
    "X_train = X_train.reshape(n_train, height, width, 1).astype('float32')\n",
    "X_val = X_val.reshape(n_val, height, width, 1).astype('float32')\n",
    "X_test = X_test.reshape(n_test, height, width, 1).astype('float32')\n",
    "\n",
    "X_train /= 255.0\n",
    "X_val /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "n_classes = 10\n",
    "\n",
    "print(n_train, 'train samples')\n",
    "print(n_val, 'validation samples')\n",
    "print(n_test, 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
    "Y_val = tf.keras.utils.to_categorical(y_val, n_classes)\n",
    "Y_test = tf.keras.utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2B-WNiQUbfOq"
   },
   "source": [
    "Create the CNN and show its architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yhOscSNPbfOt"
   },
   "outputs": [],
   "source": [
    "l0 = Input(shape=(height, width, 1), name='l0')\n",
    "\n",
    "l1 = Conv2D(9, (5, 5), padding='same', activation='relu', name='l1')(l0)\n",
    "l1_mp = MaxPooling2D(pool_size=(2, 2), name='l1_mp')(l1)\n",
    "\n",
    "l2 = Conv2D(9, (5, 5), padding='same', activation='relu', name='l2')(l1_mp)\n",
    "l2_mp = MaxPooling2D(pool_size=(2, 2), name='l2_mp')(l2)\n",
    "\n",
    "l3 = Conv2D(16, (3, 3), padding='same', activation='relu', name='l3')(l2_mp)\n",
    "l3_mp = MaxPooling2D(pool_size=(2, 2), name='l3_mp')(l3)\n",
    "\n",
    "flat = Flatten(name='flat')(l3_mp)\n",
    "\n",
    "l4 = Dense(25, activation='relu', name='l4')(flat)\n",
    "\n",
    "l5 = Dense(n_classes, activation='softmax', name='l5')(l4)\n",
    "\n",
    "model = Model(inputs=l0, outputs=l5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sP_cugPCbfO6"
   },
   "source": [
    "Define some constants and train de CNN. In order to perform the model selection process, you train each model with the train dataset and evaluate it with the validation dataset. The test set remains unseen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l8eKqD80bfPB"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_epoch = 5\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=n_epoch, verbose=1, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBX2Tc_0bfPK"
   },
   "source": [
    "Show the performance of the model. By observing the performance of your models on the validation set, you will choose a set of hyperparameters for your final model. The test set is still not used at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WeaMjl-EbfPS"
   },
   "outputs": [],
   "source": [
    "pl.plot(history.history['loss'], label='Training')\n",
    "pl.plot(history.history['val_loss'], label='Validation')\n",
    "pl.legend()\n",
    "pl.grid()\n",
    "\n",
    "score = model.evaluate(X_val, Y_val, verbose=0)\n",
    "print('Validation score:', score[0])\n",
    "print('Validation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbJZXPP3CRBX"
   },
   "source": [
    "Now that you have chosen your final model, you can finally evaluate its performance using the test set. It is important that the test set remains hidden for your model until this last step in order to have an unbiased estimate of the performance. Therefore, you should not run the following cell until you have chosen your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cGUbSJZCXSH"
   },
   "outputs": [],
   "source": [
    "final_score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('FINAL RESULTS:')\n",
    "print('Test score:', final_score[0])\n",
    "print('Test accuracy:', final_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXNZ2ZHSbfPm"
   },
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XfgRipFebfPm"
   },
   "outputs": [],
   "source": [
    "pred = model.predict_on_batch(X_test)\n",
    "pred = np.argmax(pred, axis=-1)\n",
    "me.confusion_matrix(y_test, pred)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
